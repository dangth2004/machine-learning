{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-17T16:50:11.968100Z",
     "start_time": "2024-10-17T16:50:11.882691Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:50:11.976380Z",
     "start_time": "2024-10-17T16:50:11.972150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read data\n",
    "# Change to data path on your computer\n",
    "# train path\n",
    "train_images_path = 'train-images-idx3-ubyte.gz'\n",
    "train_labels_path = 'train-labels-idx1-ubyte.gz'\n",
    "# test path\n",
    "test_images_path = 't10k-images-idx3-ubyte.gz'\n",
    "test_labels_path = 't10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "\n",
    "def get_mnist_data(images_path, labels_path, num_images, shuffle=False, _is=True, image_size=28):\n",
    "    \"\"\"\n",
    "    This shuffle param is active when .gz is downloaded at:\n",
    "    - 'http://yann.lecun.com/exdb/mnist/'\n",
    "    - This function return random num_images in 60000 or 10000\n",
    "    \"\"\"\n",
    "    # read data\n",
    "    import gzip  # to decompress gz (zip) file\n",
    "    # open file training to read training data\n",
    "    f_images = gzip.open(images_path, 'r')\n",
    "    # skip 16 first bytes because these are not data, only header infor\n",
    "    f_images.read(16)\n",
    "    # general: read num_images data samples if this parameter is set;\n",
    "    # if not, read all (60000 training or 10000 test)\n",
    "    real_num = num_images if not shuffle else (60000 if _is else 10000)\n",
    "    # read all data to buf_images (28x28xreal_num)\n",
    "    buf_images = f_images.read(image_size * image_size * real_num)\n",
    "    # images\n",
    "    images = np.frombuffer(buf_images, dtype=np.uint8).astype(np.float32)\n",
    "    images = images.reshape(real_num, image_size, image_size, )\n",
    "    # Read labels\n",
    "    f_labels = gzip.open(labels_path, 'r')\n",
    "    f_labels.read(8)\n",
    "    labels = np.zeros((real_num)).astype(np.int64)\n",
    "    # rearrange to correspond the images and labels\n",
    "    for i in range(0, real_num):\n",
    "        buf_labels = f_labels.read(1)\n",
    "        labels[i] = np.frombuffer(buf_labels, dtype=np.uint8).astype(np.int64)\n",
    "    # shuffle to get random images data\n",
    "    if shuffle is True:\n",
    "        rand_id = np.random.randint(real_num, size=num_images)\n",
    "        images = images[rand_id, :]\n",
    "        labels = labels[rand_id,]\n",
    "    # change images data to type of vector 28x28 dimentional\n",
    "    images = images.reshape(num_images, image_size * image_size)\n",
    "    return images, labels"
   ],
   "id": "50abea8458f74e11",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:50:12.451208Z",
     "start_time": "2024-10-17T16:50:12.045652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_images, train_labels = get_mnist_data(train_images_path,\n",
    "                                            train_labels_path, 5000, shuffle=True)\n",
    "test_images, test_labels = get_mnist_data(test_images_path,\n",
    "                                          test_labels_path, 10000, _is=False, shuffle=True)\n",
    "\n",
    "\n",
    "# Convert matrix to image\n",
    "def get_image(image):\n",
    "    return image.reshape(28, 28)"
   ],
   "id": "e7acb4ec96a26b61",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_188263/229319903.py:38: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  labels[i] = np.frombuffer(buf_labels, dtype=np.uint8).astype(np.int64)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:50:14.153238Z",
     "start_time": "2024-10-17T16:50:12.458839Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Standardize data\n",
    "train_image = StandardScaler().fit_transform(train_images)\n",
    "# Dimensionality reduction\n",
    "pca = PCA(n_components=100)\n",
    "train_images_pca = pca.fit_transform(train_image)"
   ],
   "id": "5a3fcf4e9927d413",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:50:14.178121Z",
     "start_time": "2024-10-17T16:50:14.170687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Multinomial Logistic Regression (Softmax) approach\n",
    "def softmax_approach(x_train, x_test, y_train, y_test):\n",
    "    # Train model\n",
    "    start = time.perf_counter()  # start counting time\n",
    "    softmax = LogisticRegression(max_iter=5000)\n",
    "    softmax.fit(x_train, y_train)\n",
    "    # Predict result\n",
    "    y_predict = softmax.predict(x_test)\n",
    "    end = time.perf_counter()  # end counting time\n",
    "    print(f'Accuracy score: {accuracy_score(y_test, y_predict)}')\n",
    "    print(f'Execution time: {end - start}s')"
   ],
   "id": "6b0593750b9b5a11",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:50:15.917383Z",
     "start_time": "2024-10-17T16:50:14.216836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split training set and validation set\n",
    "# Original data\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_images,\n",
    "                                                    train_labels, test_size=0.3, random_state=42)\n",
    "# Apply PCA method then split train - test set\n",
    "x_train_pca_split, x_test_pca_split, y_train_pca_split, y_test_pca_split = (\n",
    "    train_test_split(train_images_pca, train_labels, test_size=0.3, random_state=42))\n",
    "# Split train - test then apply PCA\n",
    "x_train_split_pca = pca.fit_transform(x_train)\n",
    "x_test_split_pca = pca.fit_transform(x_test)"
   ],
   "id": "f74f5771ac4d961e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:50:16.803380Z",
     "start_time": "2024-10-17T16:50:15.974676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Original data\n",
    "softmax_approach(x_train, x_test, y_train, y_test)"
   ],
   "id": "c540130f2ce37199",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8706666666666667\n",
      "Execution time: 0.825858407000851s\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:50:17.185701Z",
     "start_time": "2024-10-17T16:50:16.854022Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply PCA method then split train - test set\n",
    "softmax_approach(x_train_pca_split, x_test_pca_split, y_train_pca_split, y_test_pca_split)"
   ],
   "id": "222b652e2379e7b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.888\n",
      "Execution time: 0.32638319400030014s\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T16:50:22.169854Z",
     "start_time": "2024-10-17T16:50:17.264187Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split train - test then apply PCA\n",
    "softmax_approach(x_train_split_pca, x_test_split_pca, y_train, y_test)"
   ],
   "id": "ea96734fbfbec00d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.29733333333333334\n",
      "Execution time: 4.902660175001074s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dangth2004/Programming/machine-learning/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "- Độ chính xác của hướng tiếp cận giảm chiều dữ liệu rồi chia train - test khá gần so với thực hiện mô hình Hồi quy multinomial logistic (softmax) trên tập dữ liệu gốc. Tuy nhiên thời gian thực thi của hướng tiếp cận giảm chiều dữ liệu rồi chia train - test nhanh hơn rất nhiều so với thực hiện trên bộ dữ liệu gốc.\n",
    "- Hướng tiếp cận chia tập train - test rồi thực hiện giảm chiều cho độ chính xác thấp hơn đáng kể so với hướng tiếp cận giảm chiều dữ liệu rồi mới chia train - test. Thời gian thực thi giữa 2 hướng tiếp cận cũng không có sự khác biệt quá lớn.\n",
    "- Do đó, hướng tiếp cận giảm chiều dữ liệu rồi chia train - test là phù hợp với bài toán này."
   ],
   "id": "adf788f0840668ba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
