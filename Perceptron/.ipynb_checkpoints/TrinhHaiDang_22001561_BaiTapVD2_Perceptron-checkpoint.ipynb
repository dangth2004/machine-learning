{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-22T13:16:14.517589Z",
     "start_time": "2024-10-22T13:16:14.432980Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T13:16:14.553543Z",
     "start_time": "2024-10-22T13:16:14.529776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "main_df = pd.read_csv('sonar.all-data.csv', header=None)\n",
    "main_df"
   ],
   "id": "c242ad41cdd831b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  60  \n",
       "0    0.0090  0.0032   R  \n",
       "1    0.0052  0.0044   R  \n",
       "2    0.0095  0.0078   R  \n",
       "3    0.0040  0.0117   R  \n",
       "4    0.0107  0.0094   R  \n",
       "..      ...     ...  ..  \n",
       "203  0.0193  0.0157   M  \n",
       "204  0.0062  0.0067   M  \n",
       "205  0.0077  0.0031   M  \n",
       "206  0.0036  0.0048   M  \n",
       "207  0.0061  0.0115   M  \n",
       "\n",
       "[208 rows x 61 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T13:16:14.757808Z",
     "start_time": "2024-10-22T13:16:14.666231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Plot the value counts of the target column\n",
    "main_df[60].value_counts().plot(kind='barh')\n",
    "plt.show()"
   ],
   "id": "3bb2a2b13dba1c78",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T13:16:14.809700Z",
     "start_time": "2024-10-22T13:16:14.805345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the target and inputs\n",
    "y_df = main_df[60]\n",
    "target_labels = {'M': 1, 'R': -1}\n",
    "# Drop the target column from the inputs\n",
    "inputs_df = main_df.drop(60, axis=1)\n",
    "\n",
    "# Add a column of ones for the bias term\n",
    "x0 = np.ones((inputs_df.shape[0], 1))\n",
    "X = np.concatenate((x0, inputs_df), axis=1)\n",
    "\n",
    "# Map the target values to numerical labels\n",
    "targets_df = np.array([target_labels[item] for item in y_df])\n",
    "\n",
    "# Print the target labels\n",
    "print(targets_df)"
   ],
   "id": "993703d10af1ae4b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T13:16:14.904652Z",
     "start_time": "2024-10-22T13:16:14.900100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, targets_df,\n",
    "                                                    test_size=0.30, random_state=42)\n",
    "\n",
    "\n",
    "# Define h_w(x):= W^T.x + w_0 = \\bar{W}^T . \\bar{x}\n",
    "def h(w, x):\n",
    "    return np.sign(np.dot(w.T, x))\n",
    "\n",
    "\n",
    "# Stop condition\n",
    "def has_converged(X, y, w):\n",
    "    predictions = np.sign(np.dot(X, w)).flatten()  # Make predictions for all X\n",
    "    return np.array_equal(predictions, y)  # Compare predictions with true labels\n",
    "\n",
    "\n",
    "# Perceptron algorithm\n",
    "def perceptron(X, y, eta, w_init):\n",
    "    w = [w_init]\n",
    "    N = X.shape[0]\n",
    "    mis_points = []  # set of miss position points\n",
    "    max_count = 10000\n",
    "    count = 0\n",
    "    while count < max_count:\n",
    "        # mix data\n",
    "        mix_id = np.random.permutation(N)\n",
    "        for i in range(N):\n",
    "            xi = X[mix_id[i], :]  # Access row\n",
    "            yi = y[mix_id[i]]  # Direct access to the 1D array\n",
    "            count += 1\n",
    "            if h(w[-1], xi)[0] != yi:\n",
    "                mis_points.append(mix_id[i])\n",
    "                w_new = w[-1] + eta * yi * xi.reshape(-1, 1)\n",
    "                w.append(w_new)\n",
    "        if has_converged(X, y, w[-1]):\n",
    "            break\n",
    "    return w, mis_points"
   ],
   "id": "363967a461db8834",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T13:16:14.990097Z",
     "start_time": "2024-10-22T13:16:14.956767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize weights and learning rate\n",
    "d = X.shape[1]\n",
    "w_init = np.random.randn(d, 1)\n",
    "eta = 0.05\n",
    "\n",
    "# Train the perceptron\n",
    "start_perceptron = time.perf_counter()  # start counting execute time\n",
    "w, m = perceptron(x_train, y_train, eta, w_init)\n",
    "print(w[-1])\n",
    "# Predict results\n",
    "y_predict = h(w[-1], x_test.T).T\n",
    "end_perceptron = time.perf_counter()  # end counting execute time"
   ],
   "id": "311c362ac6b18c9c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.57903202e+00]\n",
      " [ 2.64638985e+00]\n",
      " [-1.54024269e-01]\n",
      " [-1.75966813e-02]\n",
      " [ 9.69423259e-01]\n",
      " [ 1.09699892e+00]\n",
      " [ 1.28753736e-01]\n",
      " [-4.53420344e-01]\n",
      " [-3.02211131e-01]\n",
      " [ 1.22760125e-02]\n",
      " [-2.81106868e-01]\n",
      " [ 2.39724994e+00]\n",
      " [ 2.59353873e-01]\n",
      " [ 9.28596270e-02]\n",
      " [ 1.65651195e-03]\n",
      " [-3.76725826e-01]\n",
      " [-2.30746618e-01]\n",
      " [ 1.87956679e-02]\n",
      " [ 3.13431597e-01]\n",
      " [-2.35521164e-02]\n",
      " [-3.12332871e-01]\n",
      " [ 5.93804714e-01]\n",
      " [-1.38117039e-01]\n",
      " [ 3.95172346e-01]\n",
      " [ 8.40214968e-01]\n",
      " [-8.68508155e-01]\n",
      " [ 7.67632420e-01]\n",
      " [-5.71662012e-01]\n",
      " [ 3.09688457e-01]\n",
      " [-2.18623238e-01]\n",
      " [ 7.87134413e-01]\n",
      " [-1.36455819e+00]\n",
      " [ 5.29250113e-01]\n",
      " [ 3.17124340e-01]\n",
      " [-1.77043637e-01]\n",
      " [-6.57367915e-02]\n",
      " [-5.48158307e-01]\n",
      " [-4.72930594e-01]\n",
      " [ 1.27418362e-01]\n",
      " [ 1.00482260e+00]\n",
      " [-1.36253655e+00]\n",
      " [ 4.17229451e-02]\n",
      " [ 2.66826752e-01]\n",
      " [ 5.38805032e-01]\n",
      " [ 8.97150914e-01]\n",
      " [ 6.21332968e-02]\n",
      " [ 4.49040757e-01]\n",
      " [ 3.10868667e-01]\n",
      " [ 2.38182311e+00]\n",
      " [-1.11250932e+00]\n",
      " [ 1.73406069e+00]\n",
      " [ 3.60071206e-01]\n",
      " [ 1.20193109e+00]\n",
      " [-8.10854777e-01]\n",
      " [ 5.52533728e-01]\n",
      " [ 8.33808496e-01]\n",
      " [-1.29993980e+00]\n",
      " [-8.47427818e-01]\n",
      " [ 2.08218798e+00]\n",
      " [ 1.02458044e+00]\n",
      " [-1.53759900e+00]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T13:16:15.016974Z",
     "start_time": "2024-10-22T13:16:15.010502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the accuracy, recall, precision score\n",
    "print(f'Accuracy score: {accuracy_score(y_test, y_predict)}')\n",
    "print(f'Recall score: {recall_score(y_test, y_predict)}')\n",
    "print(f'Precision score: {precision_score(y_test, y_predict)}')\n",
    "print(f'Execution time: {end_perceptron - start_perceptron}s')"
   ],
   "id": "eefa387e2038ccf3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7936507936507936\n",
      "Recall score: 0.7428571428571429\n",
      "Precision score: 0.8666666666666667\n",
      "Execution time: 0.03060546800000452s\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T13:16:15.069516Z",
     "start_time": "2024-10-22T13:16:15.059842Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Logistic Regression approach\n",
    "logistic_regression = LogisticRegression()\n",
    "# Train model\n",
    "start_logistic = time.perf_counter()  # start counting execute time\n",
    "logistic_regression.fit(x_train, y_train)\n",
    "# Predict results\n",
    "y_predict_logistic = logistic_regression.predict(x_test)\n",
    "end_logistic = time.perf_counter()  # end counting execute time\n",
    "# Print the accuracy, recall, precision score\n",
    "print(f'Accuracy score: {accuracy_score(y_test, y_predict_logistic)}')\n",
    "print(f'Recall score: {recall_score(y_test, y_predict_logistic)}')\n",
    "print(f'Precision score: {precision_score(y_test, y_predict_logistic)}')\n",
    "print(f'Execution time: {end_logistic - start_logistic}s')"
   ],
   "id": "f22645575a90e656",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8095238095238095\n",
      "Recall score: 0.8571428571428571\n",
      "Precision score: 0.8108108108108109\n",
      "Execution time: 0.0036589390000187905s\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-22T13:16:15.183899Z",
     "start_time": "2024-10-22T13:16:15.176429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Naive Bayes approach\n",
    "naive_bayes = GaussianNB()\n",
    "# Train model\n",
    "start_naive = time.perf_counter()  # start counting execute time\n",
    "naive_bayes.fit(x_train, y_train)\n",
    "# Predict results\n",
    "y_predict_naive = naive_bayes.predict(x_test)\n",
    "end_naive = time.perf_counter()  # end counting execute time\n",
    "# Print the accuracy, recall, precision score\n",
    "print(f'Accuracy score: {accuracy_score(y_test, y_predict_naive)}')\n",
    "print(f'Recall score: {recall_score(y_test, y_predict_naive)}')\n",
    "print(f'Precision score: {precision_score(y_test, y_predict_naive)}')\n",
    "print(f'Execution time: {end_naive - start_naive}s')"
   ],
   "id": "4e96f4a631d16a58",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7777777777777778\n",
      "Recall score: 0.6571428571428571\n",
      "Precision score: 0.92\n",
      "Execution time: 0.002014379000002009s\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Nhận xét:**\n",
    "- Thời gian thực thi: Mô hình Naive Bayes có thời gian thực thi nhanh nhất (0,002s), tiếp đến là Logistic Regression (0,003s), trong khi Perceptron có thời gian thực thi lâu nhất (0,031s). Sự chênh lệch về thời gian này có thể ảnh hưởng đến hiệu quả của mô hình khi xử lý với lượng dữ liệu lớn.\n",
    "- Độ chính xác (Accuracy): Logistic Regression có độ chính xác cao nhất (0,81), tiếp theo là Perceptron (0,79), và cuối cùng là Naive Bayes (0,78). Điều này cho thấy Logistic Regression có khả năng phân loại tổng thể tốt nhất.\n",
    "- Recall: Mô hình Logistic Regression đạt recall cao nhất (0,86), cho thấy nó có khả năng nhận diện chính xác đối tượng thuộc lớp positive tốt nhất. Perceptron cũng có recall chấp nhận được (0,74), nhưng Naive Bayes có recall thấp nhất (0,66), điều này có nghĩa là Naive Bayes bỏ sót rất khá đối tượng positive.\n",
    "- Precision: Naive Bayes có precision cao nhất (0,92), cho thấy khi dự đoán một đối tượng là positive, mô hình này thường ít nhầm lẫn hơn so với các mô hình khác. Perceptron có precision tương đối tốt (0,87), trong khi Logistic Regression có precision thấp nhất (0,81), cho thấy Perceptron có xu hướng dự đoán nhầm nhiều đối tượng negative thành positive hơn hai mô hình còn lại."
   ],
   "id": "8d1d26b93b28503c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
